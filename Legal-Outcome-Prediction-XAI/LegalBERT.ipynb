{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAW_-IkI2gcp"
      },
      "source": [
        "## **Reading the Dataset as a DataFrame**"
      ],
      "id": "rAW_-IkI2gcp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcjBRFTMJ_E1"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "BcjBRFTMJ_E1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ed8f8c6"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel('/content/drive/MyDrive/Final Year Paper Work/Complete Summarized Dataset.xlsx', header=0,index_col=0)\n",
        "\n",
        "df = df.dropna() # To remove any None values\n",
        "df.head()"
      ],
      "id": "1ed8f8c6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7KHZNmG25k_"
      },
      "source": [
        "##**Splitting the data for complete, extractive and abstractive summarized texts**"
      ],
      "id": "I7KHZNmG25k_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxRlD5af11l6"
      },
      "outputs": [],
      "source": [
        "# Complete Data\n",
        "com_sentences = df[['Judgement','Judgement Status']]\n",
        "\n",
        "# Abstractive Data\n",
        "abs_sentences = df[['Abstractive Summarized Judgements','Judgement Status']]\n",
        "\n",
        "# Extractive Data\n",
        "ext_sentences = df[['Extractive Summarized Judgements','Judgement Status']]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Train and Test Split for Complete Data\n",
        "df_train_com, df_test_com = train_test_split(com_sentences, test_size=0.25, random_state=42)\n",
        "\n",
        "# Train and Test Split for Abstractive Data\n",
        "df_train_abs, df_test_abs = train_test_split(abs_sentences, test_size=0.25, random_state=42)\n",
        "\n",
        "# Train and Test Split for Extractive Data\n",
        "df_train_ext, df_test_ext = train_test_split(ext_sentences, test_size=0.25, random_state=42)"
      ],
      "id": "GxRlD5af11l6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SF6_a-mB32An"
      },
      "source": [
        "## **Converting the Judgement Status to Categorical Values**"
      ],
      "id": "SF6_a-mB32An"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MVXTrx03Vhc"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Complete Data\n",
        "y_train_com = to_categorical(df_train_com['Judgement Status'])\n",
        "y_test_com = to_categorical(df_test_com['Judgement Status'])\n",
        "\n",
        "# Abstractive Data\n",
        "y_train_abs = to_categorical(df_train_abs['Judgement Status'])\n",
        "y_test_abs = to_categorical(df_test_abs['Judgement Status'])\n",
        "\n",
        "# Extractive Data\n",
        "y_train_ext = to_categorical(df_train_ext['Judgement Status'])\n",
        "y_test_ext = to_categorical(df_test_ext['Judgement Status'])"
      ],
      "id": "2MVXTrx03Vhc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import Statements**"
      ],
      "metadata": {
        "id": "uO6JCirMdT0X"
      },
      "id": "uO6JCirMdT0X"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_f6_O0ZcPTZj"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ],
      "id": "_f6_O0ZcPTZj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0kO7dSAPTZk"
      },
      "outputs": [],
      "source": [
        "# Import Statements\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.initializers import TruncatedNormal\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import CategoricalAccuracy\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Dropout, Layer\n",
        "from tensorflow.keras.layers import Embedding, Input, GlobalAveragePooling1D, Dense\n",
        "from tensorflow.keras.models import Sequential, Model"
      ],
      "id": "d0kO7dSAPTZk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuPFsiMYPTZk"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
        "\n",
        "# Load the tokenizer and model\n",
        "lbert_tokenizer = AutoTokenizer.from_pretrained(\"nlpaueb/legal-bert-base-uncased\")\n",
        "lbert_model = TFAutoModelForSequenceClassification.from_pretrained(\"nlpaueb/legal-bert-base-uncased\", num_labels=4)"
      ],
      "id": "zuPFsiMYPTZk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_P6QO9tNPTZk"
      },
      "source": [
        "##**1) Complete Data**"
      ],
      "id": "_P6QO9tNPTZk"
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the input (takes some time)\n",
        "# here tokenizer using from bert-base-cased\n",
        "x_train_com_lbert = lbert_tokenizer(\n",
        "    text=df_train_com['Judgement'].tolist(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=100,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)\n",
        "x_test_com_lbert = lbert_tokenizer(\n",
        "    text=df_test_com['Judgement'].tolist(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=100,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)"
      ],
      "metadata": {
        "id": "gOIt-YUtPYfk"
      },
      "id": "gOIt-YUtPYfk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids_com_lbert = x_train_com_lbert['input_ids']\n",
        "attention_mask_com_lbert = x_train_com_lbert['attention_mask']"
      ],
      "metadata": {
        "id": "h87G4wEIP6nS"
      },
      "id": "h87G4wEIP6nS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 100\n",
        "\n",
        "input_ids_com_lbert = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
        "input_mask_com_lbert = Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n",
        "embeddings = lbert_model(input_ids_com_lbert, attention_mask = input_mask_com_lbert)[0]\n",
        "out = Dense(128, activation='relu')(embeddings)\n",
        "out = tf.keras.layers.Dropout(0.1)(out)\n",
        "out = Dense(32,activation = 'relu')(out)\n",
        "y = Dense(4,activation = 'sigmoid')(out)\n",
        "\n",
        "model_com_lbert = tf.keras.Model(inputs=[input_ids_com_lbert, input_mask_com_lbert], outputs=y)\n",
        "model_com_lbert.layers[2].trainable = True"
      ],
      "metadata": {
        "id": "VmKdjtMpQKnR"
      },
      "id": "VmKdjtMpQKnR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_com_lbert = tf.keras.optimizers.legacy.Adam(learning_rate=5e-05, # this learning rate is for legal bert model , taken from huggingface website\n",
        "    epsilon=1e-08,\n",
        "    decay=0.01,\n",
        "    clipnorm=1.0)\n",
        "\n",
        "# Set loss and metrics\n",
        "loss_com_lbert = CategoricalCrossentropy(from_logits = True)\n",
        "metric_com_lbert = CategoricalAccuracy('balanced_accuracy')\n",
        "\n",
        "# Compile the model\n",
        "model_com_lbert.compile(\n",
        "    optimizer = optimizer_com_lbert,\n",
        "    loss=loss_com_lbert,\n",
        "    metrics = metric_com_lbert)"
      ],
      "metadata": {
        "id": "vbGYHXCPQeQV"
      },
      "id": "vbGYHXCPQeQV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_com_lbert = model_com_lbert.fit(\n",
        "    x ={'input_ids':x_train_com_lbert['input_ids'],'attention_mask':x_train_com_lbert['attention_mask']} ,\n",
        "    y = y_train_com,\n",
        "    validation_data = (\n",
        "    {'input_ids':x_test_com_lbert['input_ids'],'attention_mask':x_test_com_lbert['attention_mask']}, y_test_com\n",
        "    ),\n",
        "  epochs=10,\n",
        "    batch_size=64\n",
        ")"
      ],
      "metadata": {
        "id": "AtSgyZd8QvGh"
      },
      "id": "AtSgyZd8QvGh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_raw_com_lbert = model_com_lbert.predict({'input_ids':x_test_com_lbert['input_ids'],'attention_mask':x_test_com_lbert['attention_mask']})\n",
        "predicted_raw_com_lbert[0]"
      ],
      "metadata": {
        "id": "wEUyGvYeQ3oR"
      },
      "id": "wEUyGvYeQ3oR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "y_predicted_com_lbert = np.argmax(predicted_raw_com_lbert, axis = 1)\n",
        "y_true_com_lbert = df_test_com['Judgement Status']"
      ],
      "metadata": {
        "id": "nZjXfjZXQ6eu"
      },
      "id": "nZjXfjZXQ6eu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, f1_score\n",
        "print(classification_report(y_true_com_lbert, y_predicted_com_lbert))\n",
        "\n",
        "print(\"F1 Score: \",f1_score(y_true_com_lbert,y_predicted_com_lbert, average='weighted'))"
      ],
      "metadata": {
        "id": "qhBWmwGWQ80y"
      },
      "id": "qhBWmwGWQ80y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_com_lbert ={'input_ids':x_train_com_lbert['input_ids'],'attention_mask':x_train_com_lbert['attention_mask']}\n",
        "\n",
        "train_loss_com_lbert, train_accuracy_com_lbert = model_com_lbert.evaluate(x_train_com_lbert, y_train_com, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(train_accuracy_com_lbert))"
      ],
      "metadata": {
        "id": "57UvGjuZQ-r-"
      },
      "id": "57UvGjuZQ-r-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_com_lbert = {'input_ids':x_test_com_lbert['input_ids'],'attention_mask':x_test_com_lbert['attention_mask']}\n",
        "\n",
        "test_loss_com_lbert, test_accuracy_com_lbert = model_com_lbert.evaluate(x_test_com_lbert, y_test_com, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy_com_lbert))"
      ],
      "metadata": {
        "id": "qWevELapRBwQ"
      },
      "id": "qWevELapRBwQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "    plt.plot(history.history[string])\n",
        "    plt.plot(history.history['val_'+string])\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(string)\n",
        "    plt.legend([string, 'val_'+string])\n",
        "    plt.show()\n",
        "\n",
        "plot_graphs(history_com_lbert, \"balanced_accuracy\")\n",
        "plot_graphs(history_com_lbert, \"loss\")"
      ],
      "metadata": {
        "id": "KD4YyKBZREqt"
      },
      "id": "KD4YyKBZREqt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_com_lbert.save(\"/content/drive/MyDrive/Final Year Paper Work/H5 Files/COM-LEGALBERT.h5\")"
      ],
      "metadata": {
        "id": "Ldml-99zRFFM"
      },
      "id": "Ldml-99zRFFM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deV7by8qa5b1"
      },
      "source": [
        "##**2) Abstractive Summarized Data**"
      ],
      "id": "deV7by8qa5b1"
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the input (takes some time)\n",
        "# here tokenizer using from bert-base-cased\n",
        "x_train_abs_lbert = lbert_tokenizer(\n",
        "    text=df_train_abs['Abstractive Summarized Judgements'].tolist(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=100,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)\n",
        "x_test_abs_lbert = lbert_tokenizer(\n",
        "    text=df_test_abs['Abstractive Summarized Judgements'].tolist(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=100,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)"
      ],
      "metadata": {
        "id": "5P-8g_rBa5b2"
      },
      "execution_count": null,
      "outputs": [],
      "id": "5P-8g_rBa5b2"
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids_abs_lbert = x_train_abs_lbert['input_ids']\n",
        "attention_mask_abs_lbert = x_train_abs_lbert['attention_mask']"
      ],
      "metadata": {
        "id": "4WZYywOfa5b2"
      },
      "execution_count": null,
      "outputs": [],
      "id": "4WZYywOfa5b2"
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 100\n",
        "\n",
        "input_ids_abs_lbert = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
        "input_mask_abs_lbert = Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n",
        "embeddings = lbert_model(input_ids_abs_lbert, attention_mask = input_mask_abs_lbert)[0]\n",
        "out = Dense(128, activation='relu')(embeddings)\n",
        "out = tf.keras.layers.Dropout(0.1)(out)\n",
        "out = Dense(32,activation = 'relu')(out)\n",
        "y = Dense(4,activation = 'sigmoid')(out)\n",
        "\n",
        "model_abs_lbert = tf.keras.Model(inputs=[input_ids_abs_lbert, input_mask_abs_lbert], outputs=y)\n",
        "model_abs_lbert.layers[2].trainable = True"
      ],
      "metadata": {
        "id": "kmPD0Qjla5b3"
      },
      "execution_count": null,
      "outputs": [],
      "id": "kmPD0Qjla5b3"
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_abs_lbert = tf.keras.optimizers.legacy.Adam(learning_rate=5e-05, # this learning rate is for legal bert model , taken from huggingface website\n",
        "    epsilon=1e-08,\n",
        "    decay=0.01,\n",
        "    clipnorm=1.0)\n",
        "\n",
        "# Set loss and metrics\n",
        "loss_abs_lbert = CategoricalCrossentropy(from_logits = True)\n",
        "metric_abs_lbert = CategoricalAccuracy('balanced_accuracy')\n",
        "\n",
        "# Compile the model\n",
        "model_abs_lbert.compile(\n",
        "    optimizer = optimizer_abs_lbert,\n",
        "    loss=loss_abs_lbert,\n",
        "    metrics = metric_abs_lbert)"
      ],
      "metadata": {
        "id": "3UjNB19Ka5b3"
      },
      "execution_count": null,
      "outputs": [],
      "id": "3UjNB19Ka5b3"
    },
    {
      "cell_type": "code",
      "source": [
        "history_abs_lbert = model_abs_lbert.fit(\n",
        "    x ={'input_ids':x_train_abs_lbert['input_ids'],'attention_mask':x_train_abs_lbert['attention_mask']} ,\n",
        "    y = y_train_abs,\n",
        "    validation_data = (\n",
        "    {'input_ids':x_test_abs_lbert['input_ids'],'attention_mask':x_test_abs_lbert['attention_mask']}, y_test_abs\n",
        "    ),\n",
        "  epochs=10,\n",
        "    batch_size=64\n",
        ")"
      ],
      "metadata": {
        "id": "q31Py1Fba5b3"
      },
      "execution_count": null,
      "outputs": [],
      "id": "q31Py1Fba5b3"
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_raw_abs_lbert = model_abs_lbert.predict({'input_ids':x_test_abs_lbert['input_ids'],'attention_mask':x_test_abs_lbert['attention_mask']})\n",
        "predicted_raw_abs_lbert[0]"
      ],
      "metadata": {
        "id": "aUHkUB5Ka5b4"
      },
      "execution_count": null,
      "outputs": [],
      "id": "aUHkUB5Ka5b4"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "y_predicted_abs_lbert = np.argmax(predicted_raw_abs_lbert, axis = 1)\n",
        "y_true_abs_lbert = df_test_abs['Judgement Status']"
      ],
      "metadata": {
        "id": "8nwzo_PFa5b4"
      },
      "execution_count": null,
      "outputs": [],
      "id": "8nwzo_PFa5b4"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, f1_score\n",
        "print(classification_report(y_true_abs_lbert, y_predicted_abs_lbert))\n",
        "\n",
        "print(\"F1 Score: \",f1_score(y_true_abs_lbert,y_predicted_abs_lbert, average='weighted'))"
      ],
      "metadata": {
        "id": "m-2Adv_Ba5b5"
      },
      "execution_count": null,
      "outputs": [],
      "id": "m-2Adv_Ba5b5"
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_abs_lbert ={'input_ids':x_train_abs_lbert['input_ids'],'attention_mask':x_train_abs_lbert['attention_mask']}\n",
        "\n",
        "train_loss_abs_lbert, train_accuracy_abs_lbert = model_abs_lbert.evaluate(x_train_abs_lbert, y_train_abs, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(train_accuracy_abs_lbert))"
      ],
      "metadata": {
        "id": "cLFVkrKMa5b5"
      },
      "execution_count": null,
      "outputs": [],
      "id": "cLFVkrKMa5b5"
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_abs_lbert = {'input_ids':x_test_abs_lbert['input_ids'],'attention_mask':x_test_abs_lbert['attention_mask']}\n",
        "\n",
        "test_loss_abs_lbert, test_accuracy_abs_lbert = model_abs_lbert.evaluate(x_test_abs_lbert, y_test_abs, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy_abs_lbert))"
      ],
      "metadata": {
        "id": "S58gPLACa5b5"
      },
      "execution_count": null,
      "outputs": [],
      "id": "S58gPLACa5b5"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "    plt.plot(history.history[string])\n",
        "    plt.plot(history.history['val_'+string])\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(string)\n",
        "    plt.legend([string, 'val_'+string])\n",
        "    plt.show()\n",
        "\n",
        "plot_graphs(history_abs_lbert, \"balanced_accuracy\")\n",
        "plot_graphs(history_abs_lbert, \"loss\")"
      ],
      "metadata": {
        "id": "IBcnu8Zha5b5"
      },
      "execution_count": null,
      "outputs": [],
      "id": "IBcnu8Zha5b5"
    },
    {
      "cell_type": "code",
      "source": [
        "model_abs_lbert.save(\"/content/drive/MyDrive/Final Year Paper Work/H5 Files/ABS-LEGALBERT.h5\")"
      ],
      "metadata": {
        "id": "7EKhsEL3a5b5"
      },
      "execution_count": null,
      "outputs": [],
      "id": "7EKhsEL3a5b5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Q-cps4NbfCc"
      },
      "source": [
        "##**3) Extractive Summarized Data**"
      ],
      "id": "_Q-cps4NbfCc"
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the input (takes some time)\n",
        "# here tokenizer using from bert-base-cased\n",
        "x_train_ext_lbert = lbert_tokenizer(\n",
        "    text=df_train_ext['Extractive Summarized Judgements'].tolist(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=100,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)\n",
        "x_test_ext_lbert = lbert_tokenizer(\n",
        "    text=df_test_ext['Extractive Summarized Judgements'].tolist(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=100,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)"
      ],
      "metadata": {
        "id": "NIMwQajUbfCc"
      },
      "execution_count": null,
      "outputs": [],
      "id": "NIMwQajUbfCc"
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids_ext_lbert = x_train_ext_lbert['input_ids']\n",
        "attention_mask_ext_lbert = x_train_ext_lbert['attention_mask']"
      ],
      "metadata": {
        "id": "vFkMRRGubfCc"
      },
      "execution_count": null,
      "outputs": [],
      "id": "vFkMRRGubfCc"
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 100\n",
        "\n",
        "input_ids_ext_lbert = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
        "input_mask_ext_lbert = Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n",
        "embeddings = lbert_model(input_ids_ext_lbert, attention_mask = input_mask_ext_lbert)[0]\n",
        "out = Dense(128, activation='relu')(embeddings)\n",
        "out = tf.keras.layers.Dropout(0.1)(out)\n",
        "out = Dense(32,activation = 'relu')(out)\n",
        "y = Dense(4,activation = 'sigmoid')(out)\n",
        "\n",
        "model_ext_lbert = tf.keras.Model(inputs=[input_ids_ext_lbert, input_mask_ext_lbert], outputs=y)\n",
        "model_ext_lbert.layers[2].trainable = True"
      ],
      "metadata": {
        "id": "11yNFs-IbfCc"
      },
      "execution_count": null,
      "outputs": [],
      "id": "11yNFs-IbfCc"
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_ext_lbert = tf.keras.optimizers.legacy.Adam(learning_rate=5e-05, # this learning rate is for legal bert model , taken from huggingface website\n",
        "    epsilon=1e-08,\n",
        "    decay=0.01,\n",
        "    clipnorm=1.0)\n",
        "\n",
        "# Set loss and metrics\n",
        "loss_ext_lbert = CategoricalCrossentropy(from_logits = True)\n",
        "metric_ext_lbert = CategoricalAccuracy('balanced_accuracy')\n",
        "\n",
        "# Compile the model\n",
        "model_ext_lbert.compile(\n",
        "    optimizer = optimizer_ext_lbert,\n",
        "    loss=loss_ext_lbert,\n",
        "    metrics = metric_ext_lbert)"
      ],
      "metadata": {
        "id": "blh60fTMbfCd"
      },
      "execution_count": null,
      "outputs": [],
      "id": "blh60fTMbfCd"
    },
    {
      "cell_type": "code",
      "source": [
        "history_ext_lbert = model_ext_lbert.fit(\n",
        "    x ={'input_ids':x_train_ext_lbert['input_ids'],'attention_mask':x_train_ext_lbert['attention_mask']} ,\n",
        "    y = y_train_ext,\n",
        "    validation_data = (\n",
        "    {'input_ids':x_test_ext_lbert['input_ids'],'attention_mask':x_test_ext_lbert['attention_mask']}, y_test_ext\n",
        "    ),\n",
        "  epochs=10,\n",
        "    batch_size=64\n",
        ")"
      ],
      "metadata": {
        "id": "0myKN23ybfCd"
      },
      "execution_count": null,
      "outputs": [],
      "id": "0myKN23ybfCd"
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_raw_ext_lbert = model_ext_lbert.predict({'input_ids':x_test_ext_lbert['input_ids'],'attention_mask':x_test_ext_lbert['attention_mask']})\n",
        "predicted_raw_ext_lbert[0]"
      ],
      "metadata": {
        "id": "YCn0q0klbfCd"
      },
      "execution_count": null,
      "outputs": [],
      "id": "YCn0q0klbfCd"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "y_predicted_ext_lbert = np.argmax(predicted_raw_ext_lbert, axis = 1)\n",
        "y_true_ext_lbert = df_test_ext['Judgement Status']"
      ],
      "metadata": {
        "id": "e7yIFVPWbfCd"
      },
      "execution_count": null,
      "outputs": [],
      "id": "e7yIFVPWbfCd"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, f1_score\n",
        "print(classification_report(y_true_ext_lbert, y_predicted_ext_lbert))\n",
        "\n",
        "print(\"F1 Score: \",f1_score(y_true_ext_lbert,y_predicted_ext_lbert, average='weighted'))"
      ],
      "metadata": {
        "id": "oCRA3f-EbfCd"
      },
      "execution_count": null,
      "outputs": [],
      "id": "oCRA3f-EbfCd"
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_ext_lbert ={'input_ids':x_train_ext_lbert['input_ids'],'attention_mask':x_train_ext_lbert['attention_mask']}\n",
        "\n",
        "train_loss_ext_lbert, train_accuracy_ext_lbert = model_ext_lbert.evaluate(x_train_ext_lbert, y_train_ext, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(train_accuracy_ext_lbert))"
      ],
      "metadata": {
        "id": "8pYznVJRbfCd"
      },
      "execution_count": null,
      "outputs": [],
      "id": "8pYznVJRbfCd"
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_ext_lbert = {'input_ids':x_test_ext_lbert['input_ids'],'attention_mask':x_test_ext_lbert['attention_mask']}\n",
        "\n",
        "test_loss_ext_lbert, test_accuracy_ext_lbert = model_ext_lbert.evaluate(x_test_ext_lbert, y_test_ext, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy_ext_lbert))"
      ],
      "metadata": {
        "id": "S4-CiF8bbfCd"
      },
      "execution_count": null,
      "outputs": [],
      "id": "S4-CiF8bbfCd"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "    plt.plot(history.history[string])\n",
        "    plt.plot(history.history['val_'+string])\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(string)\n",
        "    plt.legend([string, 'val_'+string])\n",
        "    plt.show()\n",
        "\n",
        "plot_graphs(history_ext_lbert, \"balanced_accuracy\")\n",
        "plot_graphs(history_ext_lbert, \"loss\")"
      ],
      "metadata": {
        "id": "W-pRlVfobfCd"
      },
      "execution_count": null,
      "outputs": [],
      "id": "W-pRlVfobfCd"
    },
    {
      "cell_type": "code",
      "source": [
        "model_ext_lbert.save(\"/content/drive/MyDrive/Final Year Paper Work/H5 Files/EXT-LEGALBERT.h5\")"
      ],
      "metadata": {
        "id": "fpzf2-oEbfCe"
      },
      "execution_count": null,
      "outputs": [],
      "id": "fpzf2-oEbfCe"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "rAW_-IkI2gcp",
        "I7KHZNmG25k_",
        "SF6_a-mB32An",
        "uO6JCirMdT0X",
        "_P6QO9tNPTZk",
        "deV7by8qa5b1",
        "_Q-cps4NbfCc"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}