{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAW_-IkI2gcp"
      },
      "source": [
        "## **Reading the Dataset as a DataFrame**"
      ],
      "id": "rAW_-IkI2gcp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcjBRFTMJ_E1"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "BcjBRFTMJ_E1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ed8f8c6"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel('/content/drive/MyDrive/Final Year Paper Work/Complete Summarized Dataset.xlsx', header=0,index_col=0)\n",
        "\n",
        "df = df.dropna() # To remove any None values\n",
        "df.head()"
      ],
      "id": "1ed8f8c6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7KHZNmG25k_"
      },
      "source": [
        "##**Splitting the data for complete, extractive and abstractive summarized texts**"
      ],
      "id": "I7KHZNmG25k_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxRlD5af11l6"
      },
      "outputs": [],
      "source": [
        "# Complete Data\n",
        "com_sentences = df[['Judgement','Judgement Status']]\n",
        "\n",
        "# Abstractive Data\n",
        "abs_sentences = df[['Abstractive Summarized Judgements','Judgement Status']]\n",
        "\n",
        "# Extractive Data\n",
        "ext_sentences = df[['Extractive Summarized Judgements','Judgement Status']]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Train and Test Split for Complete Data\n",
        "df_train_com, df_test_com = train_test_split(com_sentences, test_size=0.25, random_state=42)\n",
        "\n",
        "# Train and Test Split for Abstractive Data\n",
        "df_train_abs, df_test_abs = train_test_split(abs_sentences, test_size=0.25, random_state=42)\n",
        "\n",
        "# Train and Test Split for Extractive Data\n",
        "df_train_ext, df_test_ext = train_test_split(ext_sentences, test_size=0.25, random_state=42)"
      ],
      "id": "GxRlD5af11l6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SF6_a-mB32An"
      },
      "source": [
        "## **Converting the Judgement Status to Categorical Values**"
      ],
      "id": "SF6_a-mB32An"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MVXTrx03Vhc"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Complete Data\n",
        "y_train_com = to_categorical(df_train_com['Judgement Status'])\n",
        "y_test_com = to_categorical(df_test_com['Judgement Status'])\n",
        "\n",
        "# Abstractive Data\n",
        "y_train_abs = to_categorical(df_train_abs['Judgement Status'])\n",
        "y_test_abs = to_categorical(df_test_abs['Judgement Status'])\n",
        "\n",
        "# Extractive Data\n",
        "y_train_ext = to_categorical(df_train_ext['Judgement Status'])\n",
        "y_test_ext = to_categorical(df_test_ext['Judgement Status'])"
      ],
      "id": "2MVXTrx03Vhc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import Statements**"
      ],
      "metadata": {
        "id": "tgX5U7f0dRTF"
      },
      "id": "tgX5U7f0dRTF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wi93ju645BYi"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ],
      "id": "wi93ju645BYi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7V0zX4x55X9E"
      },
      "outputs": [],
      "source": [
        "# Import Statements\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.initializers import TruncatedNormal\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import CategoricalAccuracy\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Input, Dense"
      ],
      "id": "7V0zX4x55X9E"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tB5EqsWr42Ll"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "from transformers import AutoTokenizer, TFBertModel\n",
        "\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
        "bert_model = TFBertModel.from_pretrained('bert-base-cased')"
      ],
      "id": "tB5EqsWr42Ll"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ocxms9AfHxd"
      },
      "source": [
        "##**1) Complete Data**"
      ],
      "id": "6ocxms9AfHxd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUqjD_GUhBeN"
      },
      "outputs": [],
      "source": [
        "# Tokenize the input (takes some time)\n",
        "# Here, tokenizer used is from bert-base-cased\n",
        "x_train_com_bert = bert_tokenizer(\n",
        "    text=df_train_com['Judgement'].tolist(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=100,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)\n",
        "x_test_com_bert = bert_tokenizer(\n",
        "    text=df_test_com['Judgement'].tolist(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=100,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)"
      ],
      "id": "nUqjD_GUhBeN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1U2mfVBghBeO"
      },
      "outputs": [],
      "source": [
        "input_ids_com_bert = x_train_com_bert['input_ids']\n",
        "attention_mask_com_bert = x_train_com_bert['attention_mask']"
      ],
      "id": "1U2mfVBghBeO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4q7ukD-hBeO"
      },
      "outputs": [],
      "source": [
        "# BERT Architecture\n",
        "max_len = 100\n",
        "input_ids_com_bert = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
        "input_mask_com_bert = Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n",
        "embeddings = bert_model(input_ids_com_bert, attention_mask = input_mask_com_bert)[0]\n",
        "out = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "out = Dense(128, activation='relu')(out)\n",
        "out = tf.keras.layers.Dropout(0.1)(out)\n",
        "out = Dense(32,activation = 'relu')(out)\n",
        "y = Dense(4,activation = 'sigmoid')(out)\n",
        "model_com_bert = tf.keras.Model(inputs=[input_ids_com_bert, input_mask_com_bert], outputs=y)\n",
        "model_com_bert.layers[2].trainable = True"
      ],
      "id": "l4q7ukD-hBeO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "at_J8eBbhBeP"
      },
      "outputs": [],
      "source": [
        "optimizer_bert = tf.keras.optimizers.legacy.Adam(\n",
        "    learning_rate=5e-05, # this learning rate is for bert model , taken from huggingface website\n",
        "    epsilon=1e-08,\n",
        "    decay=0.01,\n",
        "    clipnorm=1.0)\n",
        "\n",
        "# Set loss and metrics\n",
        "loss_bert = CategoricalCrossentropy(from_logits = True)\n",
        "metric_bert = CategoricalAccuracy('balanced_accuracy')\n",
        "\n",
        "# Compile the model\n",
        "model_com_bert.compile(\n",
        "    optimizer = optimizer_bert,\n",
        "    loss=loss_bert,\n",
        "    metrics = metric_bert)\n",
        "model_com_bert.summary()"
      ],
      "id": "at_J8eBbhBeP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0cF-1kQhBeP"
      },
      "outputs": [],
      "source": [
        "history_com_bert = model_com_bert.fit(\n",
        "    x ={'input_ids':x_train_com_bert['input_ids'],'attention_mask':x_train_com_bert['attention_mask']} ,\n",
        "    y = y_train_com,\n",
        "    validation_data = (\n",
        "    {'input_ids':x_test_com_bert['input_ids'],'attention_mask':x_test_com_bert['attention_mask']}, y_test_com\n",
        "    ),\n",
        "  epochs=10,\n",
        "    batch_size=64\n",
        ")"
      ],
      "id": "a0cF-1kQhBeP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NNDKkuHhBeP"
      },
      "outputs": [],
      "source": [
        "predicted_raw_com_bert = model_com_bert.predict({'input_ids':x_test_com_bert['input_ids'],'attention_mask':x_test_com_bert['attention_mask']})\n",
        "predicted_raw_com_bert[0]"
      ],
      "id": "1NNDKkuHhBeP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ct3mjSihBeP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "y_predicted_com_bert = np.argmax(predicted_raw_com_bert, axis = 1)\n",
        "y_true_com_bert = df_test_com['Judgement Status']"
      ],
      "id": "2Ct3mjSihBeP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "838QTF0ahBeQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, f1_score\n",
        "print(classification_report(y_true_com_bert, y_predicted_com_bert))\n",
        "\n",
        "print(\"F1 Score: \",f1_score(y_true_com_bert,y_predicted_com_bert, average='macro'))"
      ],
      "id": "838QTF0ahBeQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LH12MFv3hBeR"
      },
      "outputs": [],
      "source": [
        "x_train_com_bert = {'input_ids':x_train_com_bert['input_ids'],'attention_mask':x_train_com_bert['attention_mask']}\n",
        "\n",
        "train_loss_com_bert, train_accuracy_com_bert = model_com_bert.evaluate(x_train_com_bert, y_train_com, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(train_accuracy_com_bert))"
      ],
      "id": "LH12MFv3hBeR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZKsdXy5hBeR"
      },
      "outputs": [],
      "source": [
        "x_test_com_bert = {'input_ids':x_test_com_bert['input_ids'],'attention_mask':x_test_com_bert['attention_mask']}\n",
        "\n",
        "test_loss_com_bert, test_accuracy_com_bert = model_com_bert.evaluate(x_test_com_bert, y_test_com, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy_com_bert))"
      ],
      "id": "HZKsdXy5hBeR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63aLPCINhBeR"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "    plt.plot(history.history[string])\n",
        "    plt.plot(history.history['val_'+string])\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(string)\n",
        "    plt.legend([string, 'val_'+string])\n",
        "    plt.show()\n",
        "\n",
        "plot_graphs(history_com_bert, \"balanced_accuracy\")\n",
        "plot_graphs(history_com_bert, \"loss\")"
      ],
      "id": "63aLPCINhBeR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5A7VybBhBeR"
      },
      "outputs": [],
      "source": [
        "model_com_bert.save(\"/content/drive/MyDrive/Final Year Paper Work/H5 Files/COM-BERT.h5\")"
      ],
      "id": "k5A7VybBhBeR"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Calculate the \"Model Outcome\" based on the predicted values and actual \"Judgement Status\"\n",
        "y_predicted_com_bert = np.argmax(predicted_raw_com_bert, axis=1)\n",
        "model_outcome_bert = [1 if predicted == actual else 0 for predicted, actual in zip(y_predicted_com_bert, y_true_com_bert)]\n",
        "\n",
        "# Create a new DataFrame with \"Judgements\" and \"Model Outcome\" columns\n",
        "results_df_com_bert = pd.DataFrame({'Judgements': df_test_com['Judgement'], 'Model Outcome': model_outcome_bert})\n",
        "\n",
        "# Save the DataFrame to a CSV file if needed\n",
        "results_df_com_bert.to_csv('model_results.csv', index=False)"
      ],
      "metadata": {
        "id": "4YKFujy8v7Q4"
      },
      "id": "4YKFujy8v7Q4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUXyQlOn4gJf"
      },
      "source": [
        "##**2) Abstractive Summarized Data**\n"
      ],
      "id": "OUXyQlOn4gJf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCwCo-Si4V_5"
      },
      "outputs": [],
      "source": [
        "# Tokenize the input (takes some time)\n",
        "# Here, tokenizer used is from bert-base-cased\n",
        "x_train_abs_bert = bert_tokenizer(\n",
        "    text=df_train_abs['Abstractive Summarized Judgements'].tolist(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=100,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)\n",
        "x_test_abs_bert = bert_tokenizer(\n",
        "    text=df_test_abs['Abstractive Summarized Judgements'].tolist(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=100,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)"
      ],
      "id": "xCwCo-Si4V_5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlck3sbe5IHg"
      },
      "outputs": [],
      "source": [
        "input_ids_abs_bert = x_train_abs_bert['input_ids']\n",
        "attention_mask_abs_bert = x_train_abs_bert['attention_mask']"
      ],
      "id": "mlck3sbe5IHg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fA-bJC_75Uzz"
      },
      "outputs": [],
      "source": [
        "# BERT Architecture\n",
        "max_len = 100\n",
        "input_ids_abs_bert = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
        "input_mask_abs_bert = Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n",
        "embeddings = bert_model(input_ids_abs_bert, attention_mask = input_mask_abs_bert)[0]\n",
        "out = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "out = Dense(128, activation='relu')(out)\n",
        "out = tf.keras.layers.Dropout(0.1)(out)\n",
        "out = Dense(32,activation = 'relu')(out)\n",
        "y = Dense(4,activation = 'sigmoid')(out)\n",
        "model_abs_bert = tf.keras.Model(inputs=[input_ids_abs_bert, input_mask_abs_bert], outputs=y)\n",
        "model_abs_bert.layers[2].trainable = True"
      ],
      "id": "fA-bJC_75Uzz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xeahd8Gl6Joz"
      },
      "outputs": [],
      "source": [
        "optimizer_bert = tf.keras.optimizers.legacy.Adam(\n",
        "    learning_rate=5e-05, # this learning rate is for bert model , taken from huggingface website\n",
        "    epsilon=1e-08,\n",
        "    decay=0.01,\n",
        "    clipnorm=1.0)\n",
        "\n",
        "# Set loss and metrics\n",
        "loss_bert = CategoricalCrossentropy(from_logits = True)\n",
        "metric_bert = CategoricalAccuracy('balanced_accuracy')\n",
        "\n",
        "# Compile the model\n",
        "model_abs_bert.compile(\n",
        "    optimizer = optimizer_bert,\n",
        "    loss=loss_bert,\n",
        "    metrics = metric_bert)\n",
        "model_abs_bert.summary()"
      ],
      "id": "xeahd8Gl6Joz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5HwPDEvEA9u"
      },
      "outputs": [],
      "source": [
        "history_abs_bert = model_abs_bert.fit(\n",
        "    x ={'input_ids':x_train_abs_bert['input_ids'],'attention_mask':x_train_abs_bert['attention_mask']} ,\n",
        "    y = y_train_abs,\n",
        "    validation_data = (\n",
        "    {'input_ids':x_test_abs_bert['input_ids'],'attention_mask':x_test_abs_bert['attention_mask']}, y_test_abs\n",
        "    ),\n",
        "  epochs=10,\n",
        "    batch_size=64\n",
        ")"
      ],
      "id": "Y5HwPDEvEA9u"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvxO355uEVBP"
      },
      "outputs": [],
      "source": [
        "predicted_raw_abs_bert = model_abs_bert.predict({'input_ids':x_test_abs_bert['input_ids'],'attention_mask':x_test_abs_bert['attention_mask']})\n",
        "predicted_raw_abs_bert[0]"
      ],
      "id": "RvxO355uEVBP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HczNtDTGfX1J"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "y_predicted_abs_bert = np.argmax(predicted_raw_abs_bert, axis = 1)\n",
        "y_true_abs_bert = df_test_abs['Judgement Status']"
      ],
      "id": "HczNtDTGfX1J"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObrHSsr_fYa5"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, f1_score\n",
        "print(classification_report(y_true_abs_bert, y_predicted_abs_bert))\n",
        "\n",
        "print(\"F1 Score: \",f1_score(y_true_abs_bert,y_predicted_abs_bert, average='macro'))"
      ],
      "id": "ObrHSsr_fYa5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faAG8ocEfcaz"
      },
      "outputs": [],
      "source": [
        "x_train_abs_bert = {'input_ids':x_train_abs_bert['input_ids'],'attention_mask':x_train_abs_bert['attention_mask']}\n",
        "\n",
        "train_loss_abs_bert, train_accuracy_abs_bert = model_abs_bert.evaluate(x_train_abs_bert, y_train_abs, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(train_accuracy_abs_bert))"
      ],
      "id": "faAG8ocEfcaz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDvmgXs0feGk"
      },
      "outputs": [],
      "source": [
        "x_test_abs_bert = {'input_ids':x_test_abs_bert['input_ids'],'attention_mask':x_test_abs_bert['attention_mask']}\n",
        "\n",
        "test_loss_abs_bert, test_accuracy_abs_bert = model_abs_bert.evaluate(x_test_abs_bert, y_test_abs, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy_abs_bert))"
      ],
      "id": "XDvmgXs0feGk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqQSpSNifffG"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "    plt.plot(history.history[string])\n",
        "    plt.plot(history.history['val_'+string])\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(string)\n",
        "    plt.legend([string, 'val_'+string])\n",
        "    plt.show()\n",
        "\n",
        "plot_graphs(history_abs_bert, \"balanced_accuracy\")\n",
        "plot_graphs(history_abs_bert, \"loss\")"
      ],
      "id": "RqQSpSNifffG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgJX2bGggKmK"
      },
      "outputs": [],
      "source": [
        "model_abs_bert.save(\"/content/drive/MyDrive/Final Year Paper Work/H5 Files/ABS-BERT.h5\")"
      ],
      "id": "bgJX2bGggKmK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eLFckScg4Fa"
      },
      "source": [
        "## **3) Extractive Summarized Data**"
      ],
      "id": "_eLFckScg4Fa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIhKtFLUhqAc"
      },
      "outputs": [],
      "source": [
        "# Tokenize the input (takes some time)\n",
        "# Here, tokenizer used is from bert-base-cased\n",
        "x_train_ext_bert = bert_tokenizer(\n",
        "    text=df_train_ext['Extractive Summarized Judgements'].tolist(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=100,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)\n",
        "x_test_ext_bert = bert_tokenizer(\n",
        "    text=df_test_ext['Extractive Summarized Judgements'].tolist(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=100,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)"
      ],
      "id": "jIhKtFLUhqAc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0542Hb2phqAo"
      },
      "outputs": [],
      "source": [
        "input_ids_ext_bert = x_train_ext_bert['input_ids']\n",
        "attention_mask_ext_bert = x_train_ext_bert['attention_mask']"
      ],
      "id": "0542Hb2phqAo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdwmIeTuhqAo"
      },
      "outputs": [],
      "source": [
        "# BERT Architecture\n",
        "max_len = 100\n",
        "input_ids_ext_bert = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
        "input_mask_ext_bert = Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n",
        "embeddings = bert_model(input_ids_ext_bert, attention_mask = input_mask_ext_bert)[0]\n",
        "out = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "out = Dense(128, activation='relu')(out)\n",
        "out = tf.keras.layers.Dropout(0.1)(out)\n",
        "out = Dense(32,activation = 'relu')(out)\n",
        "y = Dense(4,activation = 'sigmoid')(out)\n",
        "model_ext_bert = tf.keras.Model(inputs=[input_ids_ext_bert, input_mask_ext_bert], outputs=y)\n",
        "model_ext_bert.layers[2].trainable = True"
      ],
      "id": "JdwmIeTuhqAo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjxpmBoChqAp"
      },
      "outputs": [],
      "source": [
        "optimizer_bert = tf.keras.optimizers.legacy.Adam(\n",
        "    learning_rate=5e-05, # this learning rate is for bert model , taken from huggingface website\n",
        "    epsilon=1e-08,\n",
        "    decay=0.01,\n",
        "    clipnorm=1.0)\n",
        "\n",
        "# Set loss and metrics\n",
        "loss_bert = CategoricalCrossentropy(from_logits = True)\n",
        "metric_bert = CategoricalAccuracy('balanced_accuracy')\n",
        "\n",
        "# extpile the model\n",
        "model_ext_bert.compile(\n",
        "    optimizer = optimizer_bert,\n",
        "    loss=loss_bert,\n",
        "    metrics = metric_bert)\n",
        "model_ext_bert.summary()"
      ],
      "id": "sjxpmBoChqAp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcufmLjwhqAp"
      },
      "outputs": [],
      "source": [
        "history_ext_bert = model_ext_bert.fit(\n",
        "    x ={'input_ids':x_train_ext_bert['input_ids'],'attention_mask':x_train_ext_bert['attention_mask']} ,\n",
        "    y = y_train_ext,\n",
        "    validation_data = (\n",
        "    {'input_ids':x_test_ext_bert['input_ids'],'attention_mask':x_test_ext_bert['attention_mask']}, y_test_ext\n",
        "    ),\n",
        "  epochs=10,\n",
        "    batch_size=64\n",
        ")"
      ],
      "id": "lcufmLjwhqAp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6UvQ_zshqAp"
      },
      "outputs": [],
      "source": [
        "predicted_raw_ext_bert = model_ext_bert.predict({'input_ids':x_test_ext_bert['input_ids'],'attention_mask':x_test_ext_bert['attention_mask']})\n",
        "predicted_raw_ext_bert[0]"
      ],
      "id": "A6UvQ_zshqAp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVbaGcv3hqAp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "y_predicted_ext_bert = np.argmax(predicted_raw_ext_bert, axis = 1)\n",
        "y_true_ext_bert = df_test_ext['Judgement Status']"
      ],
      "id": "mVbaGcv3hqAp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gM2lBms8hqAp"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, f1_score\n",
        "print(classification_report(y_true_ext_bert, y_predicted_ext_bert))\n",
        "\n",
        "print(\"F1 Score: \",f1_score(y_true_ext_bert,y_predicted_ext_bert, average='macro'))"
      ],
      "id": "gM2lBms8hqAp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5J2lHpmHhqAq"
      },
      "outputs": [],
      "source": [
        "x_train_ext_bert = {'input_ids':x_train_ext_bert['input_ids'],'attention_mask':x_train_ext_bert['attention_mask']}\n",
        "\n",
        "train_loss_ext_bert, train_accuracy_ext_bert = model_ext_bert.evaluate(x_train_ext_bert, y_train_ext, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(train_accuracy_ext_bert))"
      ],
      "id": "5J2lHpmHhqAq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqd5Go-4hqAq"
      },
      "outputs": [],
      "source": [
        "x_test_ext_bert = {'input_ids':x_test_ext_bert['input_ids'],'attention_mask':x_test_ext_bert['attention_mask']}\n",
        "\n",
        "test_loss_ext_bert, test_accuracy_ext_bert = model_ext_bert.evaluate(x_test_ext_bert, y_test_ext, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy_ext_bert))"
      ],
      "id": "qqd5Go-4hqAq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGttiQYphqAq"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "    plt.plot(history.history[string])\n",
        "    plt.plot(history.history['val_'+string])\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(string)\n",
        "    plt.legend([string, 'val_'+string])\n",
        "    plt.show()\n",
        "\n",
        "plot_graphs(history_ext_bert, \"balanced_accuracy\")\n",
        "plot_graphs(history_ext_bert, \"loss\")"
      ],
      "id": "nGttiQYphqAq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYC-ZicJhqAq"
      },
      "outputs": [],
      "source": [
        "model_ext_bert.save(\"/content/drive/MyDrive/Final Year Paper Work/H5 Files/EXT-BERT.h5\")"
      ],
      "id": "hYC-ZicJhqAq"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "rAW_-IkI2gcp",
        "I7KHZNmG25k_",
        "SF6_a-mB32An",
        "tgX5U7f0dRTF",
        "6ocxms9AfHxd",
        "OUXyQlOn4gJf",
        "_eLFckScg4Fa"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}