{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pE76CqlMMr5a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string\n",
        "import logging\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "import pickle\n",
        "from collections import OrderedDict\n",
        "from datetime import datetime\n",
        "\n",
        "# Initialize logging\n",
        "logging.basicConfig(filename='process_log.log', level=logging.INFO, format='%(asctime)s - %(message)s')\n",
        "\n",
        "# Download necessary NLTK datasets\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Initialize stopwords, lemmatizer, and punctuation\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "punctuation = set(string.punctuation)\n",
        "\n",
        "# Configuration variables\n",
        "CONFIG = {\n",
        "    'input_file': 'IJJD dataset.xlsx',\n",
        "    'output_embeddings_file': 'output_embeddings.xlsx',\n",
        "    'output_performance_file': 'performance_metrics.xlsx',\n",
        "    'output_combined_predictions_file': 'final_predictions.xlsx',\n",
        "    'lime_output_file': 'lime_explanation.pkl',\n",
        "    'random_seed': 42,\n",
        "    'cv': 5,\n",
        "    'test_size': 0.25,\n",
        "    'class_names': [0, 1, 2, 3],\n",
        "    'max_len':512,\n",
        "       'lime_instance': {\n",
        "    'FastText': {\n",
        "        'Abstractive_telugu_summary': 50,\n",
        "        'Abstractive_kannada_summary': 120,\n",
        "        'Extractive_telugu_summary': 65,\n",
        "        'Extractive_kannada_summary': 75,\n",
        "        'Extractive_english_summary': 80,\n",
        "        'Abstractive_tamil_summary': 95,\n",
        "        'Abstractive_english_summary': 85,\n",
        "        'Extractive_tamil_summary': 70\n",
        "    },\n",
        "    'RoBERTa': {\n",
        "        'Abstractive_telugu_summary': 85,\n",
        "        'Abstractive_kannada_summary': 130,\n",
        "        'Extractive_telugu_summary': 75,\n",
        "        'Extractive_kannada_summary': 70,\n",
        "        'Extractive_english_summary': 95,\n",
        "        'Abstractive_tamil_summary': 105,\n",
        "        'Abstractive_english_summary': 100,\n",
        "        'Extractive_tamil_summary': 80\n",
        "    },\n",
        "    'InLegalBERT': {\n",
        "        'Abstractive_telugu_summary': 100,\n",
        "        'Abstractive_kannada_summary': 115,\n",
        "        'Extractive_telugu_summary': 80,\n",
        "        'Extractive_kannada_summary': 90,\n",
        "        'Extractive_english_summary': 100,\n",
        "        'Abstractive_tamil_summary': 110,\n",
        "        'Abstractive_english_summary': 105,\n",
        "        'Extractive_tamil_summary': 95\n",
        "    },\n",
        "    'IndicBERT': {\n",
        "        'Abstractive_telugu_summary': 90,\n",
        "        'Abstractive_kannada_summary': 125,\n",
        "        'Extractive_telugu_summary': 85,\n",
        "        'Extractive_kannada_summary': 60,\n",
        "        'Extractive_english_summary': 90,\n",
        "        'Abstractive_tamil_summary': 120,\n",
        "        'Abstractive_english_summary': 115,\n",
        "        'Extractive_tamil_summary': 100\n",
        "    }\n",
        "},\n",
        "    'skip_preprocessing': ['telugu', 'kannada', 'tamil']\n",
        "}\n",
        "\n",
        "base_models = {\n",
        "    'RandomForest': RandomForestClassifier(),\n",
        "    'SVM': SVC(probability=True),\n",
        "    'DecisionTree': DecisionTreeClassifier(),\n",
        "    'XGB': XGBClassifier(),\n",
        "    'LGBM': LGBMClassifier(),\n",
        "    'MLP': MLPClassifier(),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'GaussianNB': GaussianNB()\n",
        "}\n",
        "\n",
        "# Hyperparameter grids\n",
        "param_grids = {\n",
        "    'RandomForest': {\n",
        "        'n_estimators': [50, 100, 150],\n",
        "        'max_features': [\"sqrt\", \"log2\"],\n",
        "        'max_depth': [5, 10, 15, 20],\n",
        "        'min_samples_split': [2, 3, 5, 7, 10],\n",
        "        'min_samples_leaf': [1, 2, 3, 4, 5]\n",
        "    },\n",
        "    'SVM': {\n",
        "        'C': [0.1, 1, 10, 100],\n",
        "        'kernel': ['linear', 'rbf', 'poly'],\n",
        "        'gamma': ['scale', 'auto', 0.1, 1, 10],\n",
        "        'degree': [2, 3, 4],\n",
        "        'coef0': [0.0, 0.1, 0.5, 1.0]\n",
        "    },\n",
        "    'DecisionTree': {\n",
        "        'max_depth': [5, 10, 15, 20],\n",
        "        'min_samples_split': [2, 3, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 4, 5]\n",
        "    },\n",
        "    'XGB': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'learning_rate': [0.01, 0.1, 0.2],\n",
        "        'max_depth': [3, 5, 7],\n",
        "        'subsample': [0.8, 1.0],\n",
        "        'colsample_bytree': [0.8, 1.0],\n",
        "        'min_child_weight': [1, 3, 5]\n",
        "    },\n",
        "    'LGBM': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'learning_rate': [0.01, 0.1, 0.2],\n",
        "        'max_depth': [3, 5, 7],\n",
        "        'subsample': [0.8, 1.0],\n",
        "        'colsample_bytree': [0.8, 1.0],\n",
        "        'min_child_samples': [10, 20,30]\n",
        "    },\n",
        "    'MLP': {\n",
        "         'hidden_layer_sizes': [(50, 50), (100, 100), (50,)],\n",
        "         'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
        "         'max_iter': [200, 300, 400, 500],\n",
        "         'activation': ['logistic', 'tanh', 'relu']\n",
        "    },\n",
        "    'KNN': {\n",
        "        'n_neighbors': [3, 5, 7, 9],\n",
        "        'weights': ['uniform', 'distance'],\n",
        "        'p': [1, 2]\n",
        "    },\n",
        "    'GaussianNB': {}\n",
        "}\n",
        "\n",
        "# Function to preprocess text, skipping preprocessing for telugu,tamil and kannada languages\n",
        "def preprocess_text(text, column_name):\n",
        "    lang_flags = any(lang in column_name.lower() for lang in CONFIG['skip_preprocessing'])\n",
        "\n",
        "    if lang_flags:\n",
        "        logging.info(f\"Skipping preprocessing for {column_name}\")\n",
        "        return text\n",
        "\n",
        "    text = text.lower()\n",
        "    words = word_tokenize(text)\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words and word not in punctuation]\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Function to generate FastText embeddings\n",
        "def generate_fasttext_embeddings(df, column_name, model_path='cc.en.300.bin'):\n",
        "    import fasttext \n",
        "\n",
        "    logging.info(f\"Processing FastText embeddings for column: {column_name}\")\n",
        "    try:\n",
        "        fasttext_model = fasttext.load_model(model_path)\n",
        "        df['embeddings'] = df[column_name].apply(lambda text: np.mean([fasttext_model.get_word_vector(word) for word in text.split()], axis=0))\n",
        "        embeddings = np.vstack(df['embeddings'].values)\n",
        "        return embeddings\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error generating FastText embeddings for {column_name}: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "# Function to generate RoBERTa embeddings\n",
        "def generate_roberta_embeddings(df, column_name, model_name='roberta-base'):\n",
        "    logging.info(f\"Processing RoBERTa embeddings for column: {column_name}\")\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "        def get_roberta_embedding(text):\n",
        "            inputs = tokenizer(text, return_tensors='pt',max_length=CONFIG['max_len'], truncation=True, padding='max_length')\n",
        "            outputs = model(**inputs)\n",
        "            return outputs.last_hidden_state.mean(dim=1).detach().numpy().flatten()\n",
        "\n",
        "        df['embeddings'] = df[column_name].apply(get_roberta_embedding)\n",
        "        embeddings = np.vstack(df['embeddings'].values)\n",
        "        return embeddings\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error generating RoBERTa embeddings for {column_name}: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "# Function to generate InLegalBERT embeddings\n",
        "def generate_inlegalbert_embeddings(df, column_name, model_name='nlpaueb/legal-bert-base-uncased'):\n",
        "    logging.info(f\"Processing InLegalBERT embeddings for column: {column_name}\")\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "        def get_inlegalbert_embedding(text):\n",
        "            inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
        "            outputs = model(**inputs)\n",
        "            return outputs.last_hidden_state.mean(dim=1).detach().numpy().flatten()\n",
        "\n",
        "        df['embeddings'] = df[column_name].apply(get_inlegalbert_embedding)\n",
        "        embeddings = np.vstack(df['embeddings'].values)\n",
        "        return embeddings\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error generating InLegalBERT embeddings for {column_name}: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "# Function to generate IndicBERT embeddings\n",
        "def generate_indicbert_embeddings(df, column_name, model_name='ai4bharat/indic-bert'):\n",
        "    logging.info(f\"Processing IndicBERT embeddings for column: {column_name}\")\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "        def get_indicbert_embedding(text):\n",
        "            inputs = tokenizer(text, return_tensors='pt',max_length=CONFIG['max_len'], truncation=True,padding='max_length')\n",
        "            outputs = model(**inputs)\n",
        "            return outputs.last_hidden_state.mean(dim=1).detach().numpy().flatten()\n",
        "\n",
        "        df['embeddings'] = df[column_name].apply(get_indicbert_embedding)\n",
        "        embeddings = np.vstack(df['embeddings'].values)\n",
        "        return embeddings\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error generating IndicBERT embeddings for {column_name}: {str(e)}\")\n",
        "        raise\n",
        "# Function to split data into train and test\n",
        "def split_data(embeddings, labels):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(embeddings, labels, test_size=CONFIG['test_size'], random_state=CONFIG['random_seed'])\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# Function to train base models\n",
        "def train_base_models(X_train, X_test, y_train, base_models, param_grids):\n",
        "    train_meta_features = []\n",
        "    test_meta_features = []\n",
        "    best_params = {}\n",
        "\n",
        "    for model_name, model in base_models.items():\n",
        "        try:\n",
        "            logging.info(f\"Training base model: {model_name}\")\n",
        "            param_grid = param_grids.get(model_name, {})\n",
        "            if param_grid:\n",
        "                grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=CONFIG['cv'], scoring='accuracy', n_jobs=-1)\n",
        "                grid_search.fit(X_train, y_train)\n",
        "                best_model = grid_search.best_estimator_\n",
        "                best_params[model_name] = grid_search.best_params_\n",
        "            else:\n",
        "                best_model = model.fit(X_train, y_train)\n",
        "\n",
        "            train_preds = best_model.predict(X_train).reshape(-1, 1)\n",
        "            test_preds = best_model.predict(X_test).reshape(-1, 1)\n",
        "\n",
        "            train_meta_features.append(train_preds)\n",
        "            test_meta_features.append(test_preds)\n",
        "\n",
        "            logging.info(f\"Completed training for {model_name}. Best parameters: {best_params.get(model_name, 'None')}\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error training model {model_name}: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    train_meta_features = np.hstack(train_meta_features)\n",
        "    test_meta_features = np.hstack(test_meta_features)\n",
        "\n",
        "    return train_meta_features, test_meta_features, best_params\n",
        "\n",
        "# Function to train meta-models using base-model predictions\n",
        "def train_meta_models(X_train_meta, X_test_meta, y_train_meta, y_test_meta, best_params):\n",
        "    meta_models = {}\n",
        "    for model_name, params in best_params.items():\n",
        "        try:\n",
        "            logging.info(f\"Training meta-model: {model_name} with best params: {params}\")\n",
        "            if model_name == 'RandomForest':\n",
        "                meta_models['RandomForest'] = RandomForestClassifier(**params).fit(X_train_meta, y_train_meta)\n",
        "            elif model_name == 'SVM':\n",
        "                meta_models['SVM'] = SVC(**params, probability=True).fit(X_train_meta, y_train_meta)\n",
        "            elif model_name == 'DecisionTree':\n",
        "                meta_models['DecisionTree'] = DecisionTreeClassifier(**params).fit(X_train_meta, y_train_meta)\n",
        "            elif model_name == 'XGB':\n",
        "                meta_models['XGB'] = XGBClassifier(**params).fit(X_train_meta, y_train_meta)\n",
        "            elif model_name == 'LGBM':\n",
        "                meta_models['LGBM'] = LGBMClassifier(**params).fit(X_train_meta, y_train_meta)\n",
        "            elif model_name == 'MLP':\n",
        "                meta_models['MLP'] = MLPClassifier(**params).fit(X_train_meta, y_train_meta)\n",
        "            elif model_name == 'KNN':\n",
        "                meta_models['KNN'] = KNeighborsClassifier(**params).fit(X_train_meta, y_train_meta)\n",
        "            elif model_name == 'GaussianNB':\n",
        "                meta_models['GaussianNB'] = GaussianNB().fit(X_train_meta, y_train_meta)\n",
        "\n",
        "            logging.info(f\"Successfully trained meta-model: {model_name}\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error training meta-model {model_name}: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    return meta_models\n",
        "\n",
        "# Function to evaluate meta-model performance\n",
        "def evaluate_meta_models(meta_models, X_train_meta, X_test_meta, y_train_meta, y_test_meta):\n",
        "    performance_metrics = []\n",
        "    for model_name, meta_model in meta_models.items():\n",
        "        try:\n",
        "            logging.info(f\"Evaluating meta-model: {model_name}\")\n",
        "\n",
        "            # Evaluate on training data\n",
        "            train_preds = meta_model.predict(X_train_meta)\n",
        "            train_accuracy = accuracy_score(y_train_meta, train_preds)\n",
        "            train_f1 = f1_score(y_train_meta, train_preds, average='weighted')\n",
        "\n",
        "            # Evaluate on testing data\n",
        "            test_preds = meta_model.predict(X_test_meta)\n",
        "            test_accuracy = accuracy_score(y_test_meta, test_preds)\n",
        "            test_f1 = f1_score(y_test_meta, test_preds, average='weighted')\n",
        "\n",
        "            performance_metrics.append({\n",
        "                'Model': model_name,\n",
        "                'Train Accuracy': train_accuracy,\n",
        "                'Train F1 Score': train_f1,\n",
        "                'Test Accuracy': test_accuracy,\n",
        "                'Test F1 Score': test_f1\n",
        "            })\n",
        "\n",
        "            logging.info(f\"Meta-model: {model_name} - Train Accuracy: {train_accuracy}, Train F1 Score: {train_f1}, \"\n",
        "                         f\"Test Accuracy: {test_accuracy}, Test F1 Score: {test_f1}\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error evaluating meta-model {model_name}: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    return pd.DataFrame(performance_metrics)\n",
        "\n",
        "\n",
        "# Function to generate LIME explanations for a specific embedding and column\n",
        "def generate_lime_explanation(embedding_name, column_name, df, model, tokenizer):\n",
        "    try:\n",
        "        instance_index = CONFIG['lime_instance'][embedding_name][column_name]\n",
        "        text_example = df[column_name].iloc[instance_index]\n",
        "\n",
        "        logging.info(f\"Generating LIME explanation for {embedding_name} on column {column_name}, instance index: {instance_index}\")\n",
        "\n",
        "        explainer = LimeTextExplainer(class_names=CONFIG['class_names'])\n",
        "        explanation = explainer.explain_instance(text_example, lambda x: predict_proba_base_models(x, model, tokenizer))\n",
        "\n",
        "        logging.info(\"LIME explanation generated successfully\")\n",
        "        return explanation\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error generating LIME explanation for {embedding_name}, column {column_name}: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "# Function to predict probabilities for LIME explanation\n",
        "def predict_proba_base_models(texts, model, tokenizer):\n",
        "    try:\n",
        "        embeddings = np.array([inlegalbert_embed(text, model, tokenizer) for text in texts])\n",
        "        base_model_preds = [base_model.predict(embeddings) for _, base_model in base_models.items()]\n",
        "        stacked_predictions = np.hstack([preds.reshape(-1, 1) for preds in base_model_preds])\n",
        "\n",
        "        logging.info(\"Predictions for LIME generated successfully\")\n",
        "        return stacked_predictions\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error predicting probabilities for LIME: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "# Main function to run the pipeline\n",
        "def main():\n",
        "    try:\n",
        "        # Load data\n",
        "        df = pd.read_excel(CONFIG['input_file'])\n",
        "        logging.info(\"Data loaded successfully.\")\n",
        "\n",
        "        # Generate timestamp\n",
        "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "\n",
        "        columns_to_process = [\n",
        "            'Abstractive Summarized Judgements', 'Extractive Summarized Judgements',\n",
        "            'Abstractive Summarized Judgements (Telugu)', 'Extractive Summarized Judgements (Telugu)',\n",
        "            'Abstractive Summarized Judgements (Kannada)', 'Extractive Summarized Judgements (Kannada)',\n",
        "            'Abstractive Summarized Judgements (Tamil)', 'Extractive Summarized Judgements (Tamil)'\n",
        "        ]\n",
        "\n",
        "        embedding_functions = {\n",
        "            'FastText': generate_fasttext_embeddings,\n",
        "            'RoBERTa': generate_roberta_embeddings,\n",
        "            'InLegalBERT': generate_inlegalbert_embeddings,\n",
        "            'IndicBERT': generate_indicbert_embeddings\n",
        "        }\n",
        "\n",
        "        for col in columns_to_process:\n",
        "            for embedding_name, embedding_func in embedding_functions.items():\n",
        "                logging.info(f\"Starting processing for {col} with {embedding_name} embeddings\")\n",
        "\n",
        "                # Generate embeddings\n",
        "                embeddings = embedding_func(df, col)\n",
        "\n",
        "                # Split the data\n",
        "                labels = df['Judgement Status'].values\n",
        "                X_train, X_test, y_train, y_test = split_data(embeddings, labels)\n",
        "\n",
        "                # Train base models and get predictions, also save best hyperparameters\n",
        "                train_meta_features, test_meta_features, best_params = train_base_models(X_train, X_test, y_train, base_models, param_grids)\n",
        "\n",
        "                # Train meta-models using base-model predictions\n",
        "                X_train_meta, X_test_meta, y_train_meta, y_test_meta = split_data(train_meta_features, y_train, test_size=CONFIG['test_size'])\n",
        "                meta_models = train_meta_models(X_train_meta, X_test_meta, y_train_meta, y_test_meta, best_params)\n",
        "\n",
        "                # Evaluate meta-models\n",
        "                performance_metrics_df = evaluate_meta_models(meta_models, X_train_meta, X_test_meta, y_train_meta, y_test_meta)\n",
        "                performance_metrics_df.to_excel(f'{embedding_name}_{col}_performance_metrics_{timestamp}.xlsx', index=False)\n",
        "\n",
        "                # Generate LIME explanation for a sample based on the embedding and column\n",
        "                explanation = generate_lime_explanation(embedding_name, col, df, meta_models[embedding_name], AutoTokenizer.from_pretrained('nlpaueb/legal-bert-base-uncased'))\n",
        "\n",
        "                # Save the LIME explanation\n",
        "                with open(f'{embedding_name}_{col}_lime_explanation_{timestamp}.pkl', 'wb') as file:\n",
        "                    pickle.dump(explanation, file)\n",
        "\n",
        "                logging.info(f\"Completed processing for {col} with {embedding_name} embeddings\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"An error occurred in the main pipeline: {str(e)}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
